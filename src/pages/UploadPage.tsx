import { useState, useRef, useCallback, useEffect } from 'react';
import { useNavigate } from 'react-router-dom';
import { PoseLandmarker, FilesetResolver, DrawingUtils } from '@mediapipe/tasks-vision';
import { FFmpeg } from '@ffmpeg/ffmpeg';
import { fetchFile, toBlobURL } from '@ffmpeg/util';
import { analyzeGait } from '../hooks/useGaitAnalysis';
import { useAuth, FREE_MONTHLY_LIMIT } from '../contexts/AuthContext';
import { canAnalyze, incrementUsage } from '../lib/supabase';
import type { PoseLandmark } from '../types/pose';
import type { FrameData } from '../types/pose';
import type { GaitAnalysisResult } from '../types/gait';
import './UploadPage.css';

export default function UploadPage() {
    const navigate = useNavigate();
    const { user, refreshUsage } = useAuth();
    const [videoFile, setVideoFile] = useState<File | null>(null);
    const [videoUrl, setVideoUrl] = useState<string | null>(null);
    const [isAnalyzing, setIsAnalyzing] = useState(false);
    const [progress, setProgress] = useState(0);
    const [error, setError] = useState<string | null>(null);
    const [poseLoading, setPoseLoading] = useState(true);
    const [recordedVideoUrl, setRecordedVideoUrl] = useState<string | null>(null);
    const [recordedWebmUrl, setRecordedWebmUrl] = useState<string | null>(null);
    const [isConverting, setIsConverting] = useState(false);
    const [conversionProgress, setConversionProgress] = useState(0);
    const [currentTrial, setCurrentTrial] = useState(0);
    const [totalTrials] = useState(5);

    const videoRef = useRef<HTMLVideoElement | null>(null);
    const canvasRef = useRef<HTMLCanvasElement | null>(null);
    const poseLandmarkerRef = useRef<PoseLandmarker | null>(null);
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const recordedChunksRef = useRef<Blob[]>([]);
    const ffmpegRef = useRef<FFmpeg | null>(null);
    const [ffmpegLoaded, setFfmpegLoaded] = useState(false);

    // Initialize MediaPipe
    useEffect(() => {
        const init = async () => {
            try {
                setPoseLoading(true);
                const vision = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.21/wasm'
                );
                poseLandmarkerRef.current = await PoseLandmarker.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task',
                        delegate: 'GPU'
                    },
                    runningMode: 'VIDEO',
                    numPoses: 1
                });
                setPoseLoading(false);
            } catch (err) {
                console.error('[UploadPage] MediaPipe init error:', err);
                setError('MediaPipe„ÅÆÂàùÊúüÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü');
                setPoseLoading(false);
            }
        };
        init();

        return () => {
            if (poseLandmarkerRef.current) {
                poseLandmarkerRef.current.close();
            }
        };
    }, []);

    // Initialize FFmpeg
    useEffect(() => {
        const loadFFmpeg = async () => {
            try {
                const ffmpeg = new FFmpeg();
                ffmpegRef.current = ffmpeg;

                ffmpeg.on('log', ({ message }) => {
                    console.log('[FFmpeg]', message);
                });

                ffmpeg.on('progress', ({ progress }) => {
                    setConversionProgress(Math.round(progress * 100));
                });

                const baseURL = 'https://unpkg.com/@ffmpeg/core@0.12.6/dist/umd';
                await ffmpeg.load({
                    coreURL: await toBlobURL(`${baseURL}/ffmpeg-core.js`, 'text/javascript'),
                    wasmURL: await toBlobURL(`${baseURL}/ffmpeg-core.wasm`, 'application/wasm'),
                });

                setFfmpegLoaded(true);
            } catch (err) {
                console.error('[FFmpeg] Load error:', err);
            }
        };
        loadFFmpeg();
    }, []);

    // Warn user when trying to leave during analysis
    useEffect(() => {
        const handleBeforeUnload = (e: BeforeUnloadEvent) => {
            if (isAnalyzing) {
                e.preventDefault();
                e.returnValue = 'Ëß£Êûê‰∏≠„Åß„Åô„ÄÇ„Éö„Éº„Ç∏„ÇíÈõ¢„Çå„Çã„Å®Ëß£Êûê„Åå‰∏≠Êñ≠„Åï„Çå„Åæ„Åô„ÄÇ';
                return e.returnValue;
            }
        };

        window.addEventListener('beforeunload', handleBeforeUnload);
        return () => window.removeEventListener('beforeunload', handleBeforeUnload);
    }, [isAnalyzing]);

    // Clean up URL on unmount
    useEffect(() => {
        return () => {
            if (videoUrl) {
                URL.revokeObjectURL(videoUrl);
            }
        };
    }, [videoUrl]);

    // Clean up recorded video URL
    useEffect(() => {
        return () => {
            if (recordedVideoUrl) {
                URL.revokeObjectURL(recordedVideoUrl);
            }
        };
    }, [recordedVideoUrl]);

    const handleFileSelect = useCallback((e: React.ChangeEvent<HTMLInputElement>) => {
        const file = e.target.files?.[0];
        if (!file) return;

        // Validate file type
        if (!file.type.startsWith('video/')) {
            setError('ÂãïÁîª„Éï„Ç°„Ç§„É´„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ');
            return;
        }

        // Validate file size (max 100MB)
        if (file.size > 100 * 1024 * 1024) {
            setError('„Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫„ÅØ100MB‰ª•‰∏ã„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ');
            return;
        }

        setError(null);
        setVideoFile(file);

        // Create object URL for preview
        if (videoUrl) {
            URL.revokeObjectURL(videoUrl);
        }
        const url = URL.createObjectURL(file);
        setVideoUrl(url);
    }, [videoUrl]);

    const convertToMP4 = useCallback(async (webmBlob: Blob): Promise<Blob> => {
        if (!ffmpegRef.current || !ffmpegLoaded) {
            throw new Error('FFmpeg„ÅåÂàùÊúüÂåñ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì');
        }

        setIsConverting(true);
        setConversionProgress(0);

        try {
            const ffmpeg = ffmpegRef.current;

            // Write WebM file
            await ffmpeg.writeFile('input.webm', await fetchFile(webmBlob));

            // Convert to MP4 with basic, universally compatible settings
            // Using only options that are guaranteed to work in FFmpeg WASM
            await ffmpeg.exec([
                '-i', 'input.webm',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-profile:v', 'baseline',
                '-level', '3.0',
                '-movflags', 'faststart',
                '-f', 'mp4',
                'output.mp4'
            ]);

            // Read output
            const data = await ffmpeg.readFile('output.mp4');
            const mp4Blob = new Blob([new Uint8Array(data as Uint8Array)], { type: 'video/mp4' });

            // Cleanup
            await ffmpeg.deleteFile('input.webm');
            await ffmpeg.deleteFile('output.mp4');

            setIsConverting(false);
            return mp4Blob;
        } catch (err) {
            console.error('[FFmpeg] Conversion error:', err);
            setIsConverting(false);
            throw err;
        }
    }, [ffmpegLoaded]);

    // Perform a single trial of analysis
    const performSingleTrial = useCallback(async (
        video: HTMLVideoElement,
        canvas: HTMLCanvasElement,
        poseLandmarker: PoseLandmarker,
        drawingUtils: DrawingUtils,
        _trialNumber: number,
        shouldRecord: boolean
    ): Promise<FrameData[]> => {
        const recordedFrames: FrameData[] = [];
        const duration = video.duration;

        // Reset video to start
        video.currentTime = 0;
        video.playbackRate = 1.0;

        let lastProcessedTime = -1;
        let processingComplete = false;
        const minFrameInterval = 1 / 15; // Process max 15 fps

        // Process frames during playback
        const processFrame = () => {
            if (processingComplete) return;

            const currentTime = video.currentTime;

            // Only process if enough time has passed since last frame
            if (currentTime - lastProcessedTime >= minFrameInterval) {
                const ctx = canvas.getContext('2d')!;

                // Draw frame to canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                // Detect pose
                const timestamp = performance.now();
                const results = poseLandmarker.detectForVideo(video, timestamp);

                if (results.landmarks && results.landmarks.length > 0) {
                    const landmarks = results.landmarks[0] as PoseLandmark[];
                    const worldLandmarks = (results.worldLandmarks?.[0] || landmarks) as PoseLandmark[];

                    // Draw skeleton on canvas (only if recording)
                    if (shouldRecord) {
                        drawingUtils.drawConnectors(
                            landmarks,
                            PoseLandmarker.POSE_CONNECTIONS,
                            { color: '#00FF00', lineWidth: 2 }
                        );
                        drawingUtils.drawLandmarks(
                            landmarks,
                            { color: '#FF0000', fillColor: '#FF0000', radius: 3 }
                        );

                        // Highlight knees
                        const rightKnee = landmarks[26]; // RIGHT_KNEE
                        const leftKnee = landmarks[25];  // LEFT_KNEE

                        if (rightKnee) {
                            ctx.fillStyle = 'rgba(255, 0, 255, 0.3)';
                            ctx.beginPath();
                            ctx.arc(rightKnee.x * canvas.width, rightKnee.y * canvas.height, 16, 0, 2 * Math.PI);
                            ctx.fill();
                            ctx.fillStyle = '#FF00FF';
                            ctx.beginPath();
                            ctx.arc(rightKnee.x * canvas.width, rightKnee.y * canvas.height, 8, 0, 2 * Math.PI);
                            ctx.fill();
                        }

                        if (leftKnee) {
                            ctx.fillStyle = 'rgba(0, 255, 255, 0.3)';
                            ctx.beginPath();
                            ctx.arc(leftKnee.x * canvas.width, leftKnee.y * canvas.height, 16, 0, 2 * Math.PI);
                            ctx.fill();
                            ctx.fillStyle = '#00FFFF';
                            ctx.beginPath();
                            ctx.arc(leftKnee.x * canvas.width, leftKnee.y * canvas.height, 8, 0, 2 * Math.PI);
                            ctx.fill();
                        }
                    }

                    // Record frame
                    recordedFrames.push({
                        timestamp: currentTime * 1000,
                        landmarks,
                        worldLandmarks
                    });
                }

                lastProcessedTime = currentTime;
            }

            // Update progress
            const videoProgress = Math.round((currentTime / duration) * 100);
            setProgress(videoProgress);

            // Continue processing if video is still playing
            if (!video.paused && !video.ended && currentTime < duration) {
                requestAnimationFrame(processFrame);
            } else {
                processingComplete = true;
            }
        };

        // Wait for video to complete
        await new Promise<void>((resolve, reject) => {
            video.onended = () => resolve();
            video.onerror = () => reject(new Error('ÂãïÁîª„ÅÆÂÜçÁîü‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü'));

            // Start playback and processing
            video.play().then(() => {
                requestAnimationFrame(processFrame);
            }).catch(reject);

            // Safety timeout
            setTimeout(() => {
                if (!processingComplete) {
                    video.pause();
                    resolve();
                }
            }, (duration + 10) * 1000);
        });

        // Ensure processing is complete
        processingComplete = true;
        video.pause();

        return recordedFrames;
    }, []);

    const handleAnalyze = useCallback(async () => {
        if (!videoRef.current || !canvasRef.current || !poseLandmarkerRef.current || !videoUrl || poseLoading) {
            return;
        }

        // Check usage limit before analyzing
        if (user) {
            const usageCheck = await canAnalyze(user.id);
            if (!usageCheck.allowed) {
                setError(`‰ªäÊúà„ÅÆÁÑ°ÊñôÂà©Áî®ÂõûÊï∞Ôºà${FREE_MONTHLY_LIMIT}ÂõûÔºâ„Çí‰Ωø„ÅÑÂàá„Çä„Åæ„Åó„Åü„ÄÇ„Éó„É¨„Éü„Ç¢„É†„Éó„É©„É≥„Å´„Ç¢„ÉÉ„Éó„Ç∞„É¨„Éº„Éâ„Åó„Å¶ÁÑ°Âà∂Èôê„Åß„ÅîÂà©Áî®„Åè„Å†„Åï„ÅÑ„ÄÇ`);
                return;
            }
        }

        setIsAnalyzing(true);
        setProgress(0);
        setError(null);
        setRecordedVideoUrl(null);
        setCurrentTrial(0);

        // Clear old session storage data
        sessionStorage.removeItem('recordedFrames');
        sessionStorage.removeItem('allTrialResults');

        const video = videoRef.current;
        const canvas = canvasRef.current;
        const poseLandmarker = poseLandmarkerRef.current;

        try {
            // Wait for video metadata
            await new Promise<void>((resolve, reject) => {
                if (video.readyState >= 1) {
                    resolve();
                } else {
                    video.onloadedmetadata = () => resolve();
                    video.onerror = () => reject(new Error('ÂãïÁîª„ÅÆË™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü'));
                }
            });

            const _duration = video.duration;

            // Setup canvas
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            if (!ctx) throw new Error('Canvas context not available');

            const drawingUtils = new DrawingUtils(ctx);

            // Store results from all trials
            const allTrialResults: GaitAnalysisResult[] = [];
            const allTrialFrames: FrameData[][] = [];

            // === 3Âõû„É´„Éº„ÉóËß£Êûê ===
            for (let trial = 0; trial < totalTrials; trial++) {
                setCurrentTrial(trial + 1);
                setProgress(0);

                console.log(`[Trial ${trial + 1}/${totalTrials}] Starting analysis...`);

                // Always draw skeleton for visualization, only record video on last trial
                const shouldDrawSkeleton = true;
                const shouldRecordVideo = trial === totalTrials - 1;

                // Setup MediaRecorder for canvas recording (only on last trial)
                let mediaRecorder: MediaRecorder | null = null;
                if (shouldRecordVideo) {
                    recordedChunksRef.current = [];
                    const stream = canvas.captureStream(30);
                    mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'video/webm;codecs=vp9',
                        videoBitsPerSecond: 2500000
                    });

                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            recordedChunksRef.current.push(event.data);
                        }
                    };

                    mediaRecorder.start();
                    mediaRecorderRef.current = mediaRecorder;
                }

                // Perform single trial with skeleton drawing
                const trialFrames = await performSingleTrial(
                    video, canvas, poseLandmarker, drawingUtils, trial + 1, shouldDrawSkeleton
                );

                // Stop recording if active
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();

                    // Wait for recording to complete
                    await new Promise<void>((resolve) => {
                        mediaRecorder!.onstop = async () => {
                            const webmBlob = new Blob(recordedChunksRef.current, { type: 'video/webm' });

                            // Always save WebM as guaranteed fallback
                            const webmUrl = URL.createObjectURL(webmBlob);
                            setRecordedWebmUrl(webmUrl);

                            try {
                                const mp4Blob = await convertToMP4(webmBlob);
                                const mp4Url = URL.createObjectURL(mp4Blob);
                                setRecordedVideoUrl(mp4Url);
                            } catch (err) {
                                console.error('[UploadPage] MP4 conversion error:', err);
                                // Use WebM as fallback
                                setRecordedVideoUrl(webmUrl);
                            }
                            resolve();
                        };
                    });
                }

                if (trialFrames.length === 0) {
                    console.warn(`[Trial ${trial + 1}] No frames detected`);
                    continue;
                }

                allTrialFrames.push(trialFrames);

                // Analyze this trial
                const trialAnalysis = analyzeGait(trialFrames);
                if (trialAnalysis) {
                    allTrialResults.push(trialAnalysis);
                    console.log(`[Trial ${trial + 1}] Analysis complete:`, {
                        frames: trialFrames.length,
                        stancePhases: trialAnalysis.stancePhases.length,
                        rightAmplitude: trialAnalysis.lateralThrust.rightKnee.amplitude,
                        leftAmplitude: trialAnalysis.lateralThrust.leftKnee.amplitude
                    });
                }

                // Small delay between trials to let MediaPipe reset
                if (trial < totalTrials - 1) {
                    await new Promise(resolve => setTimeout(resolve, 500));
                }
            }

            if (allTrialResults.length === 0) {
                throw new Error('3Âõû„ÅÆËß£ÊûêÂÖ®„Å¶„Åß‰∫∫Áâ©„ÅåÊ§úÂá∫„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇÂãïÁîª„Å´‰∫∫„ÅåÊò†„Å£„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ');
            }

            // Choose the best result (most frames detected = most reliable)
            const bestTrialIndex = allTrialFrames.reduce((bestIndex, frames, currentIndex, arr) =>
                frames.length > arr[bestIndex].length ? currentIndex : bestIndex
                , 0);

            const bestFrames = allTrialFrames[bestTrialIndex];
            const _bestResult = allTrialResults[bestTrialIndex];

            console.log(`[Analysis Summary] Best trial: ${bestTrialIndex + 1}/${totalTrials}`);
            console.log(`[Analysis Summary] Total successful trials: ${allTrialResults.length}`);

            // Calculate average values across all trials for stability
            const avgRightAmplitude = allTrialResults.reduce((sum, r) => sum + r.lateralThrust.rightKnee.amplitude, 0) / allTrialResults.length;
            const avgLeftAmplitude = allTrialResults.reduce((sum, r) => sum + r.lateralThrust.leftKnee.amplitude, 0) / allTrialResults.length;
            const avgAsymmetry = allTrialResults.reduce((sum, r) => sum + r.lateralThrust.asymmetryPercent, 0) / allTrialResults.length;

            console.log(`[Analysis Summary] Average values across ${allTrialResults.length} trials:`, {
                rightAmplitude: avgRightAmplitude.toFixed(2),
                leftAmplitude: avgLeftAmplitude.toFixed(2),
                asymmetry: avgAsymmetry.toFixed(1)
            });

            // Store best frames for results page
            sessionStorage.setItem('recordedFrames', JSON.stringify(bestFrames));

            // Store all trial results for comparison
            sessionStorage.setItem('allTrialResults', JSON.stringify({
                trials: allTrialResults,
                bestTrialIndex,
                averages: {
                    rightAmplitude: avgRightAmplitude,
                    leftAmplitude: avgLeftAmplitude,
                    asymmetry: avgAsymmetry
                }
            }));

            // Increment usage count after successful analysis
            if (user) {
                await incrementUsage(user.id);
                await refreshUsage();
            }

            setIsAnalyzing(false);
            setCurrentTrial(0);

        } catch (err) {
            console.error('[UploadPage] Analysis error:', err);
            setError(err instanceof Error ? err.message : 'Ëß£Êûê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü');
            setIsAnalyzing(false);
            setCurrentTrial(0);
        }
    }, [videoUrl, poseLoading, totalTrials, performSingleTrial, convertToMP4]);

    return (
        <div className="upload-page">
            <header className="upload-header">
                <button className="back-btn" onClick={() => navigate('/')}>
                    ‚Üê Êàª„Çã
                </button>
                <h1>ÂãïÁîª„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ</h1>
            </header>

            <main className="upload-main">
                {!videoFile ? (
                    <div className="upload-zone">
                        <input
                            type="file"
                            accept="video/*"
                            onChange={handleFileSelect}
                            className="file-input"
                            id="video-input"
                        />
                        <label htmlFor="video-input" className="upload-label">
                            <div className="upload-icon">üìÅ</div>
                            <p className="upload-text">ÂãïÁîª„Éï„Ç°„Ç§„É´„ÇíÈÅ∏Êäû</p>
                            <p className="upload-hint">MP4, MOV, WebMÂØæÂøúÔºàÊúÄÂ§ß100MBÔºâ</p>
                        </label>
                    </div>
                ) : (
                    <div className="preview-container">
                        <div className="video-wrapper">
                            <video
                                ref={videoRef}
                                src={videoUrl || undefined}
                                className="preview-video"
                                controls={!isAnalyzing}
                                muted
                                playsInline
                            />
                            <canvas
                                ref={canvasRef}
                                className={`analysis-overlay ${isAnalyzing ? 'visible' : ''}`}
                            />
                        </div>

                        <div className="file-info">
                            <span className="file-name">{videoFile.name}</span>
                            <button
                                className="change-file-btn"
                                onClick={() => {
                                    setVideoFile(null);
                                    if (videoUrl) URL.revokeObjectURL(videoUrl);
                                    setVideoUrl(null);
                                    if (recordedVideoUrl) URL.revokeObjectURL(recordedVideoUrl);
                                    setRecordedVideoUrl(null);
                                }}
                                disabled={isAnalyzing}
                            >
                                Â§âÊõ¥
                            </button>
                        </div>

                        {isAnalyzing && (
                            <div className="progress-container">
                                <div className="progress-bar">
                                    <div
                                        className="progress-fill"
                                        style={{ width: `${progress}%` }}
                                    />
                                </div>
                                <span className="progress-text">
                                    {currentTrial > 0 ? `Ë©¶Ë°å ${currentTrial}/${totalTrials} ` : ''}
                                    Ëß£Êûê‰∏≠... {progress}%
                                </span>
                            </div>
                        )}

                        {isConverting && (
                            <div className="progress-container">
                                <div className="progress-bar">
                                    <div
                                        className="progress-fill"
                                        style={{ width: `${conversionProgress}%` }}
                                    />
                                </div>
                                <span className="progress-text">MP4„Å´Â§âÊèõ‰∏≠... {conversionProgress}%</span>
                            </div>
                        )}

                        {recordedVideoUrl && !isAnalyzing && !isConverting && (
                            <div className="completion-actions">
                                <div className="success-message">
                                    ‚úì Ëß£Êûê„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ
                                </div>
                                <div className="action-buttons">
                                    <a
                                        href={recordedVideoUrl}
                                        download={`gaitknee-analyzed-${Date.now()}.mp4`}
                                        className="download-video-btn"
                                    >
                                        üìπ MP4„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
                                    </a>
                                    {recordedWebmUrl && (
                                        <a
                                            href={recordedWebmUrl}
                                            download={`gaitknee-analyzed-${Date.now()}.webm`}
                                            className="download-video-btn secondary"
                                        >
                                            üé¨ WebM„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
                                        </a>
                                    )}
                                    <button
                                        onClick={() => navigate('/results')}
                                        className="view-results-btn"
                                    >
                                        üìä ÁµêÊûú„ÇíË¶ã„Çã
                                    </button>
                                </div>
                                <p className="download-hint">
                                    ‚Äª MP4„ÅåÂÜçÁîü„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÅØWebMÂΩ¢Âºè„Çí„ÅäË©¶„Åó„Åè„Å†„Åï„ÅÑ
                                </p>
                            </div>
                        )}
                    </div>
                )}

                {error && (
                    <div className="error-message">
                        {error}
                    </div>
                )}
            </main>

            <footer className="upload-footer">
                <button
                    className="btn btn-primary btn-large"
                    onClick={handleAnalyze}
                    disabled={!videoFile || isAnalyzing || poseLoading}
                >
                    {poseLoading ? '„É¢„Éá„É´Ë™≠„ÅøËæº„Åø‰∏≠...' : isAnalyzing ? 'Ëß£Êûê‰∏≠...' : 'Ëß£ÊûêÈñãÂßã'}
                </button>
            </footer>
        </div>
    );
}
